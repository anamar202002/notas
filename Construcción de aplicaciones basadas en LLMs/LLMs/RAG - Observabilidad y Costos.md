
El consumo de LLMs se mide principalmente en **tokens**, lo que introduce un modelo de costos diferente al de infraestructuras tradicionales.

La lectura enfatiza que FinOps debe integrarse desde el diseño:
- Selección del modelo adecuado para cada tarea.
- Diseño de prompts eficientes.
- Uso de caching y reutilización de respuestas.

La observabilidad permite:
- Monitorear consumo y latencia.
- Detectar anomalías.
- Ajustar dinámicamente el sistema para mantener viabilidad económica.

Un sistema RAG sin observabilidad tiende a escalar costos de forma impredecible.
